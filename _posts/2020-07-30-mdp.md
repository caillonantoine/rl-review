---
layout: post
title: Finite MDP
published: false
---

# Agent-Environment Interface

A Markov Decision Process (MDP) is a classical formalization of sequential decision making.

> In MDPs, actions influence not just immediate rewards, but also subsequent situations, or states, and through those future rewards.

In MDPs, we estimate the action value $$q^*(s,a)$$ for an action $$a$$ or the state value $$v^*(s)$$ for the optimal action $$a$$.

> MDPs are meant to be a straightforward framing of the problem of learning from interaction to achieve a goal. The learner and decision maker is called the agent. The thing it interacts with, comprising everything outside the agent, is called the environment.


